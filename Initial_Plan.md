# Open OnDemand Pilot Plan

## Overview of Steps

### Pre-pilot

- Basic documentation
- Pre-pilot survey

### Mid-Pilot 

- Mid-pilot survey
- Usage data analysis
- Review of support provided
- Adjustment plans
 - Alterations to service
 - Documentation updates

### Post-Pilot

- Post-pilot survey
- Usage data analysis
- Review of support provided
- Short-term and mid-term plans for production service
 - Continuation decision
 - Alterations to service
 - Documentation updates


## Steps

### Basic documentation

This should be sufficient to get users started with the service. It doesn't have to be ferociously detailed, and it should probably be mostly in how-to form. 

For example:

 - how to log in
 - how to access each component, listing them and briefly describing what they do
 - how to transfer files

### Pre-pilot survey

This should aim to establish how comfortable pilot users are with various parts of the current service provision, to let us match them with user stories and establish what parts are useful for whom.

It should also establish what they currently use the service for, in terms of applications.

### Mid-pilot survey

This should aim to establish what experiences people have had using the service so far -- what they've found useful, what they haven't used or haven't liked, and whether there are any things that people have missed, that we've missed, or that can be fixed for the remainder of the pilot.

Critical analysis should be applied to determine actions that can be taken based on that feedback.

### Usage data analysis

This should be performed at the mid-pilot analysis stage and the post-pilot analysis stage.

It should look at the logs on the service and in Azure, to see:
 - who logged on
 - who didn't
 - what the load on the service was like
 - whether there are any common errors that can be fixed
 - whether data on what components were used match up with what we see in the surveys

### Review of support provided

This should be performed at the mid-pilot analysis stage and the post-pilot analysis stage.

It should aim to determine how much work was created in supporting the service, and categorise it, with an aim to determining:

 - what types of support work are involved in user setup
 - what types of support work are involved in on-going use
 - how much of each type is created, and is it sustainable
 - what documentation could be created to reduce the support burden
 - what changes could be made to reduce the support burden

There will be some support unique to the pilot environment: this should be categorised as such so that we can discount it where possible from the consideration of on-going support costs.

### Adjustment plans

This should be the result of the mid-pilot analysis: any changes we've decided to make based on feedback, surveys, and reviews of other stored data.

It is likely to involve creating more documentation, to cover areas that users have found difficult or poorly-explained.

It may involve advising people, if they've skipped over parts of the service that could solve any problems identified, however advice given here should be considered for inclusion in part of the documentation process.

It may also involve removing service components that were particularly problematic, if they don't seem worth including for the rest of the pilot.

In the worst case, it may involve discontinuing the pilot early.

### Post-pilot planning

This should include a synthesis of all the data collected so far, and a decision on whether to continue the service development to production.

It should also include the development of a roadmap of short and medium-term plans for changes based on feedback, including documentation.

## Surveys

For the textual questions and general ideas, it may be a good idea to inform pilot users of them in advance so they can collect thoughts as they go.

### Initial

- Establish familiarity with existing services
- Establish general level of computational competence
- Establish expectations for the pilot

### Mid

- What users liked about the service so far
- What users disliked about the service
- What they've found awkward or difficult
- Do you intend to keep using the service
- How useful have you found the service components so far

Do this per component, with a numeric rating out of 5. (Couched in verbal terms -- liked a lot/very useful down to strongly disliked/not useful at all.) (Remember to include "did not try".)

### End

Similar to mid, but also maybe something like:

- Which of these components would you use instead of existing ones?
- Which of these would you encourage others to use instead of existing ones, and why?

## Pilot users

Ideally we would like a fairly diverse set of users to try things, but it's difficult to get people to take time to properly try things.

It's even more difficult to get people to fill in surveys.

We don't really have any good figurative "carrots".

## To do

These steps need to be completed before the pilot can begin.

- Assemble either pilot users or a mechanism to invite people to be pilot users
- Identify survey mechanism
- Complete specification for initial survey
- Draught mid and post surveys -- these don't need to be completed when pilot begins, but we should know what kind of questions we intend to ask
- Write initial documentation and put in-place
- Ensure any usage data that is intended to be used is being collected

